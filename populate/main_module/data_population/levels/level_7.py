"""
N√≠vel 7: Participa√ß√µes e coment√°rios (MAIS CR√çTICO).

Popula Participacoes e Comentarios - maior volume de dados.
"""

import time
import random
from sqlalchemy.orm import Session
from faker import Faker

from ...config import DataConfig
from ...batch_inserter import BatchInserter
from models import Usuario, Video
from aux_func import generate_participacoes, generate_comentarios


def populate_level_7(session: Session, fake: Faker, config: DataConfig, inserter: BatchInserter) -> float:
    """
    Popula entidades do n√≠vel 7: Participa√ß√µes e Coment√°rios.
    
    Args:
        session: Sess√£o do SQLAlchemy
        fake: Inst√¢ncia do Faker
        config: Configura√ß√£o de volume de dados
        inserter: Inst√¢ncia do BatchInserter
        
    Returns:
        Tempo de execu√ß√£o em segundos
    """
    print(f"üì¶ [7/9] Gerando {config.n_participacoes:,} participa√ß√µes e {config.n_comentarios:,} coment√°rios...")
    inicio = time.time()
    
    # Carrega apenas os IDs dos v√≠deos (muito mais eficiente em mem√≥ria)
    print("    Carregando IDs dos v√≠deos...")
    video_ids = [row[0] for row in session.query(Video.id).all()]
    
    # Carrega IDs dos usu√°rios
    usuario_ids = [row[0] for row in session.query(Usuario.id).all()]
    
    # Para participa√ß√µes, precisamos carregar objetos Video em lotes menores
    print("    Gerando Participa√ß√µes...")
    # Reusa a l√≥gica de sele√ß√£o de streamers (assumindo que n_streamers est√° configurado)
    streamer_ids = random.sample(usuario_ids, min(config.n_streamers, len(usuario_ids)))
    
    # Carrega v√≠deos e streamers em lotes apenas para participa√ß√µes
    FETCH_BATCH = 5_000  # Reduzido para economizar mem√≥ria
    videos_objs = []
    for i in range(0, len(video_ids), FETCH_BATCH):
        batch_ids = video_ids[i:i+FETCH_BATCH]
        videos_objs.extend(session.query(Video).filter(Video.id.in_(batch_ids)).all())
    
    streamers = []
    for i in range(0, len(streamer_ids), FETCH_BATCH):
        batch_ids = streamer_ids[i:i+FETCH_BATCH]
        streamers.extend(session.query(Usuario).filter(Usuario.id.in_(batch_ids)).all())
    
    # Participa√ß√µes (assinatura: videos, streamers, count - SEM fake)
    participacoes_list = generate_participacoes(videos_objs, streamers, config.n_participacoes)
    session.add_all(participacoes_list)
    session.flush()
    del participacoes_list, videos_objs, streamers
    
    # Coment√°rios (MAIOR VOLUME) com estado
    print("    Gerando Coment√°rios em lotes (pode demorar)...")
    num_seq_state = {}
    
    # Coment√°rios com commits peri√≥dicos
    inserted_comments = 0
    batch_size = config.batch_sizes.large
    total_batches = (config.n_comentarios + batch_size - 1) // batch_size
    
    for batch_num in range(1, total_batches + 1):
        current_size = min(batch_size, config.n_comentarios - inserted_comments)
        
        # Amostra IDs de usu√°rios (n√£o precisa carregar objetos completos)
        sample_size = min(current_size, len(usuario_ids))
        sample_usuario_ids = random.sample(usuario_ids, sample_size)
        
        # Gera coment√°rios usando apenas IDs (muito mais eficiente)
        com_batch = generate_comentarios(fake, current_size, video_ids, sample_usuario_ids, num_seq_state)
        session.add_all(com_batch)
        session.flush()
        
        inserted_comments += len(com_batch)
        progress = (inserted_comments / config.n_comentarios) * 100
        print(f"    [{batch_num}/{total_batches}] {progress:.1f}% - {inserted_comments:,}/{config.n_comentarios:,} Coment√°rios", end='\r')
        
        del com_batch
        
        # Commit a cada 5 lotes
        if batch_num % 5 == 0:
            session.commit()
    
    print()
    
    tempo_nivel = time.time() - inicio
    print(f"    ‚úì N√≠vel 7 conclu√≠do em {tempo_nivel:.2f}s\n")
    
    return tempo_nivel
